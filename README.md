# âš¡ SÃ¼perbilgisayar ile Derin Ã–ÄŸrenme Optimizasyon Deneyleri: CIFAR-10 & ResNet

Bu proje, **NVIDIA P100 GPU**â€™lu sÃ¼perbilgisayar ortamÄ±nda, **SLURM job scheduler** ve **PyTorch Lightning** kullanÄ±larak **CIFAR-10 veri seti** ve **ResNet mimarisi** Ã¼zerinde farklÄ± **optimizasyon algoritmalarÄ±, batch boyutlarÄ± ve paralel eÄŸitim yÃ¶ntemlerinin** test edilmesini ve karÅŸÄ±laÅŸtÄ±rÄ±lmasÄ±nÄ± kapsamaktadÄ±r.  

AmaÃ§, eÄŸitim sÃ¼relerini ve doÄŸruluk deÄŸerlerini etkileyen faktÃ¶rleri sistematik olarak analiz ederek, **en verimli eÄŸitim kombinasyonlarÄ±nÄ± belirlemektir**.  

---

## ğŸš€ Proje Ã–zeti
- **Veri Seti & Model:**  
  - CIFAR-10 veri seti  
  - ResNet mimarisi (PyTorch Lightning ile uygulanmÄ±ÅŸtÄ±r)  

- **Deneysel Ã‡alÄ±ÅŸmalar:**  
  - FarklÄ± **optimizasyon algoritmalarÄ±** test edildi (SGD, Adam, RMSProp vb.)  
  - Ã‡eÅŸitli **batch boyutlarÄ±** denendi  
  - **Paralel eÄŸitim yÃ¶ntemleri** (DDP vb. yÃ¶ntemler) uygulandÄ±  
  - **SLURM scriptleri** ile sÃ¼perbilgisayar Ã¼zerinde deneyler otomatikleÅŸtirildi  

- **KarÅŸÄ±laÅŸÄ±lan Zorluk:**  
  - **BÃ¼yÃ¼k batch boyutlarÄ±nda OOM (Out of Memory) hatalarÄ±** oluÅŸtu.  
  - Bu problem **Gradient Accumulation** ile giderildi.  

- **SonuÃ§:**  
  - EÄŸitim performansÄ±nÄ± artÄ±ran en verimli kombinasyonlar belirlendi.  
  - DoÄŸruluk ve eÄŸitim sÃ¼resi aÃ§Ä±sÄ±ndan **optimum ayarlar** ortaya Ã§Ä±karÄ±ldÄ±.  

---

## ğŸ“‚ KullanÄ±lan Teknolojiler
- **Python**  
- **PyTorch Lightning** â†’ Model tanÄ±mlama, eÄŸitim ve logging  
- **CUDA** â†’ GPU hÄ±zlandÄ±rma  
- **NVIDIA P100 GPU** â†’ HPC ortamÄ±  
- **SLURM** â†’ Job scheduling ve GPU tahsisi  
- **PyTorch DDP (Distributed Data Parallel)** â†’ Paralel eÄŸitim  

---

## ğŸ”¬ Ã‡alÄ±ÅŸma AdÄ±mlarÄ±
1. **Veri HazÄ±rlama** â†’ CIFAR-10 veri seti indirildi ve normalize edildi  
2. **Model TanÄ±mlama** â†’ ResNet PyTorch Lightning  implement edildi  
3. **Optimizasyon Denemeleri** â†’ SGD, Adam, RMSProp vb. algoritmalar denendi  
4. **Batch Boyutu Analizi** â†’ KÃ¼Ã§Ã¼k ve bÃ¼yÃ¼k batch boyutlarÄ± test edildi  
5. **Paralel EÄŸitim** â†’ Lightning Trainer + SLURM + DDP kullanÄ±larak multi-GPU eÄŸitim  
6. **OOM Sorunu ve Ã‡Ã¶zÃ¼m** â†’ Gradient Accumulation ile bellek sorunu Ã§Ã¶zÃ¼ldÃ¼  
7. **Performans Ã–lÃ§Ã¼mÃ¼** â†’ EÄŸitim sÃ¼resi ve doÄŸruluk deÄŸerleri karÅŸÄ±laÅŸtÄ±rÄ±ldÄ±  

---

## ğŸ“Š SonuÃ§lar
- **KÃ¼Ã§Ã¼k batch boyutlarÄ±:** Daha stabil eÄŸitim, fakat uzun sÃ¼rede yakÄ±nsama  
- **BÃ¼yÃ¼k batch boyutlarÄ±:** Daha hÄ±zlÄ± eÄŸitim, fakat OOM sorunlarÄ±  
- **Gradient Accumulation:** OOM problemini Ã§Ã¶zdÃ¼, eÄŸitim performansÄ±nÄ± artÄ±rdÄ±  
- **PyTorch Lightning + SLURM:** Deneylerin otomatik, tekrarlanabilir ve Ã¶lÃ§eklenebilir ÅŸekilde yÃ¼rÃ¼tÃ¼lmesini saÄŸladÄ±  
- **En verimli kombinasyonlar:** DoÄŸruluk ve eÄŸitim sÃ¼resi arasÄ±nda optimum dengeyi saÄŸladÄ±  

---
